---
format: 
  revealjs:
    slide-number: true
    # code-link: true
    highlight-style: a11y
    chalkboard: true
    theme: 
      - ../../meds-slides-styles.scss
editor_options: 
  chunk_output_type: console
---

## {#title-slide data-menu-title="Title Slide" background="#053660"} 

[EDS 430: Part 6.2]{.custom-title}

[*Testing*]{.custom-subtitle}

<hr class="hr-teal">

[Week 2 | February 2^nd^, 2024]{.custom-subtitle3}

---

##  {#testing data-menu-title="~~~ Testing ~~~" background="#047C90"}

<div class="page-center vertical-center">
<p class="custom-subtitle bottombr">{{< fa file-code title="a file with the code symbol, </>, on it" >}} Testing</p>
<p class="caption-text">*Creating automated tests for your apps can save time and effort, ensuring that they continue working as expected.*</p>
</div>

---

##  {#LO-testing data-menu-title="Learning Objectives - Testing"}

[{{< fa book-open title="an open book" >}} Learning Objectives for Testing]{.slide-title}

<hr>

<p class="body-text-l teal-text bottombr">After this section, you should:</p>

. . . 

[{{< fa angle-right title="a bullet point" >}}]{.teal-text} understand some of the reasons why apps break and the benefit of having automated tests

. . . 

[{{< fa angle-right title="a bullet point" >}}]{.teal-text} have a basic understanding of how to use the `{shinytest2}` package to create regression tests

. . . 

[{{< fa angle-right title="a bullet point" >}}]{.teal-text} know how to rerun tests

. . . 

[{{< fa angle-right title="a bullet point" >}}]{.teal-text} know how to update tests

. . . 

[{{< fa angle-right title="a bullet point" >}}]{.teal-text} TBD

. . . 

<p class="body-text-l teal-text topbr">Packages introduced:</p> 

. . . 

[{{< fa box-open title="an open box" >}}]{.teal-text} `{shinytest2}`:  provides tools for creating and running automated tests on Shiny applications

---

##  {#shiny-workflow data-menu-title="Shiny workflow"}

[This workflow should look a bit familiar . . .]{.slide-title2}

<hr>

1. Add / adjust some reactivity
2. Click "Run App"
3. Manually experiment with (i.e. informally test) the new feature to see if it works 
5. Rinse & repeat

<br>

. . . 

But what if you have 20 apps? 

<br>

. . . 

Or many team members? 


<br>

. . . 

**It becomes increasingly challenging to remember all the features you need to test, or how each works.** Things can also get lost in translation with manual testing (e.g. can you explain to your coworker(s) *all* of your app's features and make sure that they manually test it properly?).

::: {.footer}
Slide adapted from Barret Schloerke's rstudio::conf(2022) talk, [`{shinytest2}`: Unit testing for Shiny applications](https://www.youtube.com/watch?v=DMgAW4m5aTI)
:::

---

##  {#why-test data-menu-title="Why test?"}

[Why test our Shiny apps?]{.slide-title}

<hr>

It's almost inevitable that our app(s) will (at some point) break -- there are lots of reasons why this happens, but to name a few:

. . . 

<p class="body-text-s topbr">[{{< fa angle-right title="a bullet point" >}}]{.teal-text} **an upgraded R package(s)** has a different behavior (this includes `{shiny}`) -- this is especially relevant for those apps hosted on servers, where server software (including packages) may be updated by system administrators</p>

. . . 

<p class="body-text-s topbr">[{{< fa angle-right title="a bullet point" >}}]{.teal-text} **you make changes to your app** (e.g. add new features, refactor code)</p>

. . . 

<p class="body-text-s topbr">[{{< fa angle-right title="a bullet point" >}}]{.teal-text} **an external data source stops working** or returns data in a different format than that expected by your app</p>

. . .

<br>

Manually testing Shiny apps is takes a lot of time and effort, is often inconsistent, and doesn't scale well (e.g. for larger apps, many apps, or for larger teams of collaborators).

. . . 

<br>

**It can save a lot of time and headache (for you *and* your collaborators) to have an automated system that checks if your app is working as expected.**

---

Different levels/types of tests:

- **Unit tests** test individual functions, components, modules of your app (e.g. can your app handle the expected data? does your user see what you expect them to see?)
- **Integration tests** test how your app works with external systems (e.g. APIs) 

<https://www.atlassian.com/continuous-delivery/software-testing/types-of-software-testing>

---

##  {#shinytest2 data-menu-title="{shinytest2}"}

[Enter the `{shinytest2}` package]{.slide-title}

<hr>

The [`{shinytest2}` package](https://rstudio.github.io/shinytest2/articles/shinytest2.html) provides useful tools for **unit testing** Shiny apps. This process is also known as [**regression testing**](https://en.wikipedia.org/wiki/Regression_testing), since we'll be testing existing app behavior for consistency over time (we don't want app behavior to regress).

:::: {.columns}

::: {.column width="50%"}

<br>

<p class="body-text">From the `{shinytest2}` documentation:</p>

<p class="body-text-s quote-text-bg">"*`{shinytest2}` uses `{testthat}`’s snapshot-based testing strategy. The first time it runs a set of tests for an application, it performs some scripted interactions with the app and takes one or more snapshots of the application’s state. These snapshots are saved to disk so that future runs of the tests can compare their results to them.*"</p> 
:::

::: {.column width="50%"}
```{r}
#| eval: true
#| echo: false
#| out-width: "60%"
#| fig-align: "center"
#| fig-alt: "A hex that's split down the middle horizontally. The top half is the blue Shiny hex and the bottom half looks like the red {testthat} hex, except it reads 'test2'."
knitr::include_graphics("images/part6/shinytest2-hex.png")
```
:::

::::

[With `{shinytest2}`, we can interact with our app via the "app recorder" and our test code will be automatically generated for us. We can then rerun tests to check for consistency as we iterate on our app.]{.body-text-s}

::: {.footer}
`{shinytest2}` uses [`{chromote}`](https://rstudio.github.io/chromote/) to render your app in a headless [Chromium browser](https://www.chromium.org/chromium-projects/) -- by default, it uses Google Chrome, so make sure you have that installed on your OS! 
:::

---

##  {#setting-stage data-menu-title="Setting the stage"}

[Let's imagine . . .]{.slide-title}

<hr>

[Your boss has tasked you with building a Shiny app, and asks that you begin with a feature that greets users by name. **Create a new folder, `testing-app/`, in your GitHub repo and add the following files:**]{.body-text-s}

<!-- --- -->

<!-- ##  {#starting-app data-menu-title="Starting app"} -->

<!-- [Let's start with the following app]{.slide-title} -->

<!-- <hr> -->

::: {.panel-tabset}
## `global.R`

```{r filename="testing-app/global.R"}
#| eval: false
#| echo: true
# load libraries ----
library(shiny)
```

## `ui.R`

```{r filename="testing-app/ui.R"}
#| eval: false
#| echo: true
ui <- fluidPage(

  # Feature 1 ------------------------------------------------------------------

  h3("Feature 1"),

  # fluidRow (Feature 1: greeting) ----
  fluidRow(

    # greeting sidebarLayout ----
    sidebarLayout(

      # greeting sidebarPanel ----
      sidebarPanel(

        textInput(inputId = "name_input",
                  label = "What is your name?"),

        actionButton(inputId = "greeting_button_input",
                     label = "Greet"),

      ), # END greeting sidebarPanel

      # greeting mainPanel ----
      mainPanel(

        textOutput(outputId = "greeting_output"),

      ) # END greeting mainPanel

    ) # END greeting sidebarLayout

  ), # END fluidRow (Feature 1: greeting)
  
) # END fluidPage 
```

## `server.R`

```{r filename="testing-app/server.R"}
#| eval: false
#| echo: true
server <- function(input, output) {
  
  # Feature 1 ------------------------------------------------------------------

  output$greeting_output <- renderText({

    req(input$greeting_button_input) # req(): textOutput doesn't appear until button is first pressed
    paste0("Hello ", isolate(input$name_input), "!") # isolate(): prevents textOutput from updating until button is pressed again

  }) 
}
```

:::

---

##  {#run-ft1-app data-menu-title="Run the app"}

[Manually test your app and make note of how it works]{.slide-title3}

<hr>

```{r}
#| eval: true
#| echo: false
#| out-width: "80%"
#| fig-align: "center"
knitr::include_graphics("images/part6/ft1-explore.gif")
```

<br>

::: {.center-text}
Let's say that you are satisfied with your work (yay!) and are now ready to write some automated tests to ensure consistent behavior as you continue to build out additional features.
:::

---

##  {#ft1-assumptions data-menu-title="Feature 1 assumptions"}

[Write down your assumptions]{.slide-title}

<hr>

Before we dive into writing any tests, it's super helpful to inspect your app and, *importantly* jot down any assumptions it makes of both the inputs and outputs.

<br>

I find it easiest to consider which **actions** can be taken, and what the **expected outputs** (aka assertions) in the app's final state should be. 

<br>

```{r}
# countdown::countdown(
#   minutes = 2,
#   # left = 0, right = 0,
#   # Fanfare when it's over
#   # play_sound = TRUE,
#   color_border              = "#FFFFFF",
#   color_text                = "#7aa81e",
#   color_running_background  = "#7aa81e",
#   color_running_text        = "#FFFFFF",
#   color_finished_background = "#ffa07a",
#   color_finished_text       = "#FFFFFF",
#   font_size = "2em",
#   )
```

. . . 

[**For example:**]{.teal-text .body-text-l} 

| Action(s)                                                                                                               | Expectation(s)                                                           |
|-------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|
| Type [some text value] in text box > click Greet button                                                                 | Greeting output is "Hello [some text value]!"                            |
| Type [some text value] in text box > click Greet button > type [some other text value] in text box > click Greet button | Greeting output is "Hello [some text value]!", then updates to "Hello [some other text value]!" |
| Click Greet button                                                                                                      | Greeting output is "Hello !"                                             |

<br>

. . . 

::: {.center-text .body-text-m}
Now we're ready to actually *test* these assumptions!
:::

---

##  {#assumptions-note data-menu-title="A note on assumptions"}

[One more important note (actually, a few)]{.slide-title}

<hr>

<br>

::: {.center-text}
As much as you try, **testing will never be exhaustive**. You can only test for scenarios that you think of.
:::

<br>

. . . 

::: {.center-text}
The goal is to **put yourself in the shoes of a user**, and test scenarios that you think your users will encounter. If you test those use-cases, you'll cover the majority of expectations.
:::

<br>

. . . 

::: {.center-text}
As users interact with your app, **they'll stumble upon and reveal use-cases / scenarios that you hadn't tested for**...and you can update your app / write tests accordingly.
:::

<br>

. . . 

::: {.center-text}
Over time, **your ability to identify both how users will interact with your app *and* what to test will improve**.
:::

---

##  {#testing-procedure data-menu-title="Testing procedure"}

[Test your assumptions using the `{shinytest2}` workflow]{.slide-title2}

<hr>

<br>

[**Generally speaking, that workflow looks something like this:**]{.teal-text}

<br>

. . . 

[**(1)**]{.teal-text} Run `shinytest2::record_test(<app-directory>)` in your Console to launch the app recorder in a browser window

<br>

. . . 

[**(2)**]{.teal-text} Interact with your application and tell the recorder to make an expectation of the app's state, which will record `input`, `output`, and `exported` values. 

<!-- (e.g. an expected value when inputX is updated) on the state at various points -->

<br>

. . . 

[**(3)**]{.teal-text} Give your test a unique name and quit the recorder to save and execute your tests

<br>

. . . 

::: {.center-text .body-text-m}
We'll repeat this workflow to test each of our three assumptions listed on the previous slide.
:::

---

##  {#chromote-timeout data-menu-title="chromote time out"}

[FYI (a warning about chromote time outs)]{.slide-title2}

<hr>

<br>
<br>
<br>

If you receive the following error message after running, `shinytest2::record_test("testing-app")`, you'll need to restart R:

<br>

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
Caused by error:
! Chromote: timed out waiting for response to command Target.createTarget
```

<br>

It's a pretty annoying error, which seems to be an [ongoing issue](https://github.com/rstudio/chromote/issues/94) with `{chromote}`. R may be slow to restart (and I've had to restart numerous times {{< fa face-sad-tear title="a sad face with a tear" >}}).

---

##  {#ft1-test1 data-menu-title="Feature 1, test 1"}

[Let's test our first assumption . . .]{.slide-title}

<hr>

...which is that when a user types [some text value] into the text box and clicks the Greet button (**i.e. the actions**), the greeting output will return `Hello [some text value]!` (**i.e. the expectation**). We'll substitute a known value (e.g. "Sam") for [some text value] in our test.

<br>

:::: {.columns}

::: {.column width="50%"}
```{r}
#| eval: true
#| echo: false
#| out-width: "100%"
#| fig-align: "center"
knitr::include_graphics("images/part6/one-name-greeting.gif")
```
:::

::: {.column width="50%"}
[**Steps:**]{.teal-text}

[[**(1)**]{.teal-text} Run `shinytest2::record_test("testing-app")` in the Console]{.body-text-s}

[[**(2)**]{.teal-text} Type `Sam` into the text box > click the Greet button > click Expect Shiny Values]{.body-text-s}

[[**(3)**]{.teal-text} Give the test a unique name (e.g. `one-name-greeting`) > click Save test and exit]{.body-text-s}

[[**(4)**]{.teal-text} The test recorder will quit, and your test will automatically execute (it should pass!)]{.body-text-s}

:::
::::

::: {.center-text .body-text-s}
Notice that your actions (e.g. typing text, clicking the button) are recorded as code in the right-hand panel -- this is your test code, and it'll be saved when you quit the recorder.
:::

<!-- --- -->

<!-- What are assumptions? -->

<!-- ```{r} -->
<!-- ex_function <- function(a, b) { -->
<!--   c <- a + b -->
<!--   return(c) -->
<!-- } -->
<!-- ``` -->

<!-- - inputs -- we want to make sure that inputs are consistent and follow the expected format -->
<!--   - # of inputs  -->
<!--   - order of inputs (if not using keyword args) -->
<!--   - type of input (e.g. is `a` a string? a number? can it be anything?) -->
<!--   - absence of inputs (e.g. are there default values) -->
<!-- - logic  -->
<!--   - does this handle the expected inputs (e.g. if i give it something that it should handle, will it do it as I expect) -->
<!--   - does it handle unexpected inputs (e.g. return NULL, throw error message) -->
<!-- - return (what does the function return?) -->
<!--   - make sure that it returns the right data type (e.g. string, numeric) -->

<!-- what different variations of my inputs impact my output? -->
<!-- - you'll never think of all variations -->

<!-- --- -->

<!-- ##  {#assumptions data-menu-title="Write down assumptions"} -->

<!-- [Write down assumptions]{.slide-title2} -->

<!-- <hr> -->

<!-- [**Example 1: Greeting**]{.body-text-m .teal-text} -->

<!-- - input: does the user supply text values? -->
<!-- - logic/output: does the app print, "Hello <input>!" -->

<!-- - Expected output: user's input is prefixed with "Hello" and suffixed with "!". The text is then displayed -->
<!-- - an assumption is that a user can input numbers, paragraphs, etc (anything that is valid as a text input) -->
<!-- - when the greet button is clicked, it'll display what the user has input (even with successive inputs) -->

<!-- [**Example 2: Upload & summarize data**]{.body-text-m .teal-text} -->

<!-- - input:  -->
<!--   - user supplies a csv file -->
<!-- - output:  -->
<!--   - if the csv column has expected column headers, it will: -->
<!--     - rename columns -->
<!--     - remove rows with missing values (NA) -->
<!--     - average values in each column -->
<!--     - return summary data frame -->
<!--   - if the csv does not have the expected column headers, it will: -->
<!--     - return a message that tells the user the file is not as expected -->
<!--   - if the csv does not have any values, it will: -->
<!--     - return a message that tells the user the file is not as expected -->
<!--   - successive csv uploads shows the most recent data -->

<!-- [**Example 3: Reactive plot**]{.body-text-m .teal-text} -->

<!-- - input:  -->
<!--   - shows the user what they can choose: the user can select `Adelie`, `Chinstrap`, and/or `Gentoo` -->
<!--   - when user chooses something, does the right thing happen - when user deselects a species, it's removed from the plot -->
<!--   - when a user selects a species, it's added to the plot  -->
<!--   - when the user deselects all, a message prompts user to select at least one species -->
<!--   - does the user see the correct default selection -- all species are selected by default -->
<!-- - output:  -->
<!--   - selected species will be plotted, deselected species will not be plotted -->
<!--   - if not species are selected, a message will alert user to select species -->

<!-- --- -->

<!-- ##  {#testing-procedure data-menu-title="Testing procedure"} -->

<!-- [Testing using `{shinytest2}`]{.slide-title} -->

<!-- <hr> -->

<!-- **Recording tests requires the following steps:** -->

<!-- . . .  -->

<!-- [[**(1)**]{.teal-text} Run `shinytest2::record_test(<app-directory>)` to launch the app recorder in a browser window]{.body-text-s} -->

<!-- . . .  -->

<!-- [[**(2)**]{.teal-text} Interact with your application and tell the recorder to make an expectation (e.g. an expected value when inputX is updated) on the state at various points]{.body-text-s} -->

<!-- . . .  -->

<!-- [[**(3)**]{.teal-text} Quit the recorder to save and execute your tests]{.body-text-s} -->

<!-- . . .  -->

<!-- <br> -->

<!-- **To test *our* app specifically, we'll do the following:** -->

<!-- [[**(1)**]{.teal-text} run `shinytest2::record_test("testing-app")` in the console to launch the recorder in a browser window]{.body-text-s} -->

<!-- [[**(2)**]{.teal-text} interact with your app by first typing a name (e.g. Sam), then pressing the "Greet" button to display the output text]{.body-text-s} -->

<!-- [[**(3)**]{.teal-text} click the **Expect Shiny values** button in the recorder app sidebar to set an expectation (this will record inputs, outputs, and exported values)]{.body-text-s} -->

<!-- [[**(4)**]{.teal-text} give your test a name in the recorder app sidebar, then click **Save test and exit** - this will save the recorded test and setup the testing infrastructure, if it doesn't exit already]{.body-text-s} -->

<!-- --- -->

<!-- ##  {#creating-test1-example data-menu-title="Creating our first test"} -->

<!-- [Creating our first test]{.slide-title} -->

<!-- <hr> -->

<!-- Following the steps on the previous slide, creating your test should look similar to this: -->

<!-- <br> -->

<!-- ```{r} -->
<!-- #| eval: true -->
<!-- #| echo: false -->
<!-- #| out-width: "100%" -->
<!-- #| fig-align: "center" -->
<!-- #| fig-alt: "A user begins recording a test by typing shinytest2::record_test('testing_app') in the RStudio console, which opens up the app in an iframe with the recorder in a pane to the right. The user types 'Sam' into the text box, clicks the 'Greet' button, then clicks 'Expect Shiny values' in the recorder. Finally, the user names and saves the test, which then runs automatically once the recorder is quit." -->
<!-- knitr::include_graphics("images/part6/sam-test.gif") -->
<!-- ``` -->

<!-- <br> -->

<!-- **Note:** Your test is automatically run as soon as you save and exit the recorder. See the results of your test in your console (it should pass!). -->

---

##  {#test-auto-executes data-menu-title="Tests auto execute"}

[Your test should automatically run (and pass!)]{.slide-title2}

<hr>

After quitting the test recorder, the following will happen: 

- [a test script will be saved in `testing-app/tests/testthat/test-shinytest2.R`]{.body-text-s}
- [if you're running in the RStudio IDE, `test-shinytest2.R` will automatically open in the editor]{.body-text-s} 
- [`shinytest2::test_app()` is run behind the scenes to execute the test script]{.body-text-s}

You should see the following in your RStudio Console: 

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
• Saving test runner: tests/testthat.R
• Saving test file: tests/testthat/test-shinytest2.R
✔ Adding 'shinytest2::load_app_env()' to 'tests/testthat/setup-shinytest2.R'
• Running recorded test: tests/testthat/test-shinytest2.R
✔ | F W  S  OK | Context
✔ |   2      1 | shinytest2 [1.4s]                                                         
───────────────────────────────────────────────────────────────────────────────────────────
Warning (test-shinytest2.R:7:3): {shinytest2} recording: one-name-greeting
Adding new file snapshot: 'tests/testthat/_snaps/one-name-greeting-001_.png'

Warning (test-shinytest2.R:7:3): {shinytest2} recording: one-name-greeting
Adding new file snapshot: 'tests/testthat/_snaps/one-name-greeting-001.json'
───────────────────────────────────────────────────────────────────────────────────────────

══ Results ════════════════════════════════════════════════════════════════════════════════
Duration: 1.5 s

[ FAIL 0 | WARN 2 | SKIP 0 | PASS 1 ]
```

---

##  {#test-folder data-menu-title="Explore the tests/ folder"}

[Understanding the contents of `tests/`]{.slide-title}

<hr>

The first time you record a test, `{shinytest2}` generates number of directories / subdirectories, along with a bunch of files. The next few slides explain these in more detail.

<br>

After creating your first test, your repo structure should look something like this:
```{md}
#| eval: false
#| echo: true
#| code-line-numbers: false
.
├── testing-app/                                  
│   └── global.R                     
│   └── ui.R                         
│   └── server.R                      
│   └── tests/                    # generated the first time you record and save a test    
│      └── testthat.R             # see note below
│      └── testthat/     
│         └── setup-shinytest2.R  # see note below
│         └── test-shinytest2.R   # see slide 15
│         └── snaps/               
│            └── shinytest2/      
│               └── *001.json     # see slide X
│               └── *001_.png     # see slide X 
```

- [`testthat.R`: includes the code, `shinytest2::test_app()`, which is executed when you click the **Run Tests** button in RStudio]{.body-text-s}
- [`setup-shinytest2.R`: includes the code, `shinytest2::load_app_env()`, which loads any application support files (e.g. `global.R` and / or anything inside `R/`) into the testing environment]{.body-text-s}

---

##  {#test-shinytest2 data-menu-title="The test file"}

[`test-shinytest2.R` (test code)]{.slide-title}

<hr>

[All tests will be saved to `tests/testthat/test-shinytest2.R`. Yours should look similar to the code below (sans annotations). You may have a different viewport height / width (depending on the size of your viewport when you recorded your test), and if you mistyped / deleted any characters in the textInput, you'll see multiple `app$set_inputs()` statements, reflecting these actions:]{.body-text-s}

<br>

```{r filename="testing-app/tests/testthat/test-shinytest2.R"}
#| eval: false
#| echo: true
library(shinytest2)

# runs our test
test_that("{shinytest2} recording: one-name-greeting", {
  
  # start Shiny app in a new R session along with chromote's headless browser that's used to simulate user actions
  app <- AppDriver$new(name = "one-name-greeting", height = 838, width = 1298)
  
  # set the textInput (with Id `name_input`) to the value `Sam`
  app$set_inputs(name_input = "Sam")
  
  # click the actionButton (with Id `greeting_button_input`)
  app$click("greeting_button_input")
  
  # save the expected input, output, and export values to a JSON snapshot and generates a debug screenshot of the app
  app$expect_values()
})
```

---

##  {#snaps data-menu-title="The _snaps/ folder"}

[The `snaps/` folder]{.slide-title}

<hr>

[When `shinytest2::test_app()` runs your test code (`test-shinytest2.R`), it plays back the specified actions (e.g. setting the textInput to `Sam`, then clicking the Greet button), and records your application's resulting state as a snapshot. Snapshots are saved to the `tests/testthat/shinytest2/_snaps/` folder. You should see two different snapshot files:]{.body-text-s}

<br>

:::: {.columns}

::: {.column width="50%"}
::: {.center-text .body-text-s}
`one-name-greeting-001_.png`, a screenshot of the app when `app$expect_values()` was called:
```{r}
#| eval: true
#| echo: false
#| out-width: "80%"
#| fig-align: "center"
knitr::include_graphics("images/part6/one-name-greeting.png")
```
:::
:::

::: {.column width="50%"}
::: {.center-text .body-text-s}
`one-name-greeting-001.json`, a [JSON](https://www.json.org/json-en.html) representation of the state of the app when `app$expect_values()` was called:
:::

```{json}
#| eval: false
#| echo: true
{
  "input": {
    "greeting_input": 1,
    "name_input": "Sam"
  },
  "output": {
    "greeting_output": "Hello Sam!"
  },
  "export": {

  }
}
```
:::

::::

::: {.footer}
We don't have any exported values in our app, and we won't be covering those here. Read more about exported values in the [`{shinytest2}` documentation](https://rstudio.github.io/shinytest2/articles/in-depth.html#exported-values).
:::

---

##  {#test-recap data-menu-title="Test recap"}

[A quick recap of our test files]{.slide-title}

<hr>

- **You can think of your test as a *recipe* for `{shinytest2}` to follow to simulate user actions (i.e. inputs).** 
  - [These simulations are performed programmatically whenever you click **Run Test**.]{.body-text-s}

. . . 

- **The JSON file defines your test's expected outputs given known inputs.**
  - [When you rerun your test, the same user actions (inputs) are simulated and the resulting outputs are compared against prior snapshots. We expect the resulting outputs to be the same each time. If the resulting outputs differ from our expectations, the test will fail.]{.body-text-s}

. . .

- **The screenshot (`*_.png` file) can be used to visually inspect your app's state at the time of your test.**
  - [The `*_.png` file differs from a `*.png` file (which we did not capture). `*.png` files are screenshots of the application from `app$expect_screenshot()` (i.e. by clicking *Expect screenshot* in the app recorder), which you can use to ensure that the visual state of the application does not change. If subsequent screenshots differ (even by just a pixel!), your test will fail. This type of testing is quite brittle, and we won't be covering it further.]{.body-text-s}

. . .

::: {.center-text .teal-text}
**All of the above files should be tracked with `git`.**
:::

<!-- (ignore any `_.new.png` files) -->

---

##  {#rerun-tests data-menu-title="Rerun the test"}

[Rerun your test]{.slide-title}

<hr>

Rerun your test by clicking on the **Run Tests** button, which is visible when `test-shinytest2.R` is open. They should all still pass (we haven't changed anything since our first test run)!

```{r}
#| eval: true
#| echo: false
#| out-width: "100%"
#| fig-align: "center"
knitr::include_graphics("images/part6/rerun-test.png")
```

---

##  {#test-other-assumptions data-menu-title="Test remaining assumptions"}

[Test our remaining assumptions]{.slide-title}

<hr>

<br>
<br>
<br>

| Action(s)                                                                                       | Expectation(s)                                                           |
|-------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------|
| {{< fa square-check title="a checked box" >}} Type [some text value] in text box > click Greet button                                          | Greeting output is "Hello [some text value]!"                            |
| {{< fa square title="an unchecked box" >}} Type [some text value] in text box > click Greet button > type [some other text value] in text box > click Greet button | Greeting output is "Hello [some text value]!", then updates to "Hello [some other text value]!" |
| {{< fa square title="an unchecked box" >}} Click Greet button                                                                              | Greeting output is "Hello !"                                             |

```{r}
countdown::countdown(
  minutes = 3,
  # left = 0, right = 0,
  # Fanfare when it's over
  # play_sound = TRUE,
  color_border              = "#FFFFFF",
  color_text                = "#7aa81e",
  color_running_background  = "#7aa81e",
  color_running_text        = "#FFFFFF",
  color_finished_background = "#ffa07a",
  color_finished_text       = "#FFFFFF",
  font_size = "2em",
  )
```

---

##  {#feature1-complete-tests data-menu-title="All feature 1 tests"}

[`test-shinytest2.R` should now look like this:]{.slide-title2}

<hr>

[Or at least fairly close to this (maybe you chose different names to test with or had a different viewport size):]{.body-text-s}

```{r filename="testing-app/tests/testthat/test-shinytest2.R"}
#| eval: false
#| echo: true
library(shinytest2)

test_that("{shinytest2} recording: one-name-greeting", {
  app <- AppDriver$new(name = "one-name-greeting", height = 1335, width = 1126)
  app$set_inputs(name_input = "Sam")
  app$click("greeting_button_input")
  app$expect_values()
})


test_that("{shinytest2} recording: consecutive-name-greeting", {
  app <- AppDriver$new(name = "consecutive-name-greeting", height = 961, width = 1322)
  app$set_inputs(name_input = "Sam")
  app$click("greeting_button_input")
  app$expect_values()
  app$set_inputs(name_input = "Kat")
  app$click("greeting_button_input")
  app$expect_values()
})


test_that("{shinytest2} recording: no-name-greeting", {
  app <- AppDriver$new(name = "no-name-greeting", height = 837, width = 1294)
  app$click("greeting_button_input")
  app$expect_values()
})
```

::: {.center-text .body-text-s}
You can rerun all your tests at once by clicking the **Run Tests** button again (they should all pass!).
:::

---

##  {#improve-feature1 data-menu-title="Improving feature 1 functionality"}

[Your boss requests an improvement on feature 1]{.slide-title2}

<hr>

[Your boss is excited to see your progress, but would love to see an informative message pop up when a user clicks the Greet button without first typing in a name (currently, clicking the Greet button without typing a name will return "Hello !"... which is a bit odd). You make the following update to your app:]{.body-text-s}

```{r filename="testing-app/server.R"}
#| eval: false
#| echo: true
server <- function(input, output) {
  
  # Feature 1 ------------------------------------------------------------------
  # wait for user to click the Greet button before returning the message
  observe({
    
    # if the user does not type anything, return the message, "Please type a name, then click the Greet button."
    if (nchar(input$name_input) == 0) {
      output$greeting_output <- renderText({
        "Please type a name, then click the Greet button."
      })
      
      # if the user does type a name, return the greeting, "Hello [name]!"
    } else {
      output$greeting_output <- renderText({
        paste0("Hello ", isolate(input$name_input), "!")
      })
    }
  }) |>
    
    # TODO: add description here
    bindEvent(input$greeting_button_input)
}
```

---

##  {#no-name-greeting-breaks data-menu-title="Your test breaks!"}

[Rerun your tests after making your update]{.slide-title}

<hr>

Our first two tests pass, but **the third one failed** {{< fa face-frown title="a frowning face" >}}. You'll see something like this to start:

```{r}
#| eval: true
#| echo: false
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("images/part6/failed-no-name-greeting.png")
```

::: {.center-text}
Click on the **Output tab** for more information on why the test failed (see next slide).
:::

---

##  {#output-tab data-menu-title="Output tab"}

[The Output tab tells us what caused our test to fail]{.slide-title2}

<hr>

[There's a lot of helpful information here, but lines 6-7 tell us that our `no-name-greeting` test failed, while lines 17-27 here tell us exactly what changed:]{.body-text-s}

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "6-7,17-27"
==> Testing R file using 'testthat'

Loading required package: shiny
[ FAIL 1 | WARN 1 | SKIP 0 | PASS 3 ]

── Failure (test-shinytest2.R:25:3): {shinytest2} recording: no-name-greeting ──
Snapshot of `file` to 'shinytest2/no-name-greeting-001.json' has changed
Run testthat::snapshot_review('shinytest2/') to review changes
Backtrace:
    ▆
 1. └─app$expect_values() at test-shinytest2.R:25:3
 2.   └─shinytest2:::app_expect_values(...)
 3.     └─shinytest2:::app__expect_snapshot_file(...)
 4.       ├─base::withCallingHandlers(...)
 5.       └─testthat::expect_snapshot_file(...)

── Warning (test-shinytest2.R:25:3): {shinytest2} recording: no-name-greeting ──
Diff in snapshot file `shinytest2no-name-greeting-001.json`
< before                                                                   
> after                                                                    
@@ 5,5 / 5,5 @@                                                            
    },                                                                     
    "output": {                                                            
<     "greeting_output": "Hello !"                                         
>     "greeting_output": "Please type a name, then click the Greet button."
    },                                                                     
    "export": {                                                            
[ FAIL 1 | WARN 1 | SKIP 0 | PASS 3 ]
Warning messages:
1: package ‘testthat’ was built under R version 4.3.1 
2: package ‘shiny’ was built under R version 4.3.1 

Test complete
```

---

##  {#update-expectations data-menu-title="Update expected results"}

[We'll want to update our expected results]{.slide-title}

<hr>

[**Our test correctly failed (the expected output was different)!** But we'll want to update our test's expected output so that it reflects the changes we made to our app (i.e. that when a user clicks the Greet button without first typing a name, the text "Please type a name before clicking the Greet button." is printed).]{.body-text-s}

. . .

<br>

[We can use use `testthat::snapshot_review()`, which opens a Shiny app for visually comparing differences between snapshots and accepting (or rejecting) updates.]{.body-text-s}

. . .

<br>

[**Steps:**]{.teal-text .body-text-m}

1. Install the [`{diffviewer}` package](https://github.com/r-lib/diffviewer)

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
install.packages("diffviewer")
```

2. Run the following in your Console to launch the widget: 

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
testthat::snapshot_review(path = "testing-app/tests/testthat/")
```

---

##  {#snapshot-review data-menu-title="snapshot_review()"}

[Explore and accept the updated test expectations]{.slide-title2}

<hr>

The app allows for a few different ways to view snapshot diffs. Click Accept for both the PNG and JSON files, then close the window:

<br>

```{r}
#| eval: true
#| echo: false
#| out-width: "80%"
#| fig-align: "center"
knitr::include_graphics("images/part6/snapshot-review.gif")
```

---

##  {#updated-snapshots data-menu-title="Updated snapshots"}

[Check out your updated snapshots]{.slide-title2}

<hr>

Check out `no-name-greeting-001_.png` and `no-name-greeting-001.json`, which should be updated to reflect the new test expectations.

```{r}
#| eval: true
#| echo: false
#| out-width: "80%"
#| fig-align: "center"
knitr::include_graphics("images/part6/updated-snapshots.png")
```


---

##  {#feature2-code data-menu-title="Feature 2 code"}

[Your boss requests another feature!]{.slide-title}

<hr>

[Your boss is jazzed about your latest improvements, and now asks that you add a file uploader which accepts a standardized CSV file (predictable headings / data types) then averages values by column. You update your app:]{.body-text-s}

::: {.panel-tabset}
## `global.R`

```{r filename="testing-app/global.R"}
#| eval: false
#| echo: true
# load libraries ----
library(shiny)
library(tidyverse)
```

## `ui.R`

```{r filename="testing-app/ui.R"}
#| eval: false
#| echo: true
ui <- fluidPage(

  # Feature 1 ------------------------------------------------------------------

  h3("Feature 1"),

  # fluidRow (Feature 1: greeting) ----
  fluidRow(

    # greeting sidebarLayout ----
    sidebarLayout(

      # greeting sidebarPanel ----
      sidebarPanel(

        textInput(inputId = "name_input",
                  label = "What is your name?"),

        actionButton(inputId = "greeting_button_input",
                     label = "Greet"),

      ), # END greeting sidebarPanel

      # greeting mainPanel ----
      mainPanel(

        textOutput(outputId = "greeting_output"),

      ) # END greeting mainPanel

    ) # END greeting sidebarLayout

  ), # END fluidRow (Feature 1: greeting)
  
  tags$hr(),

  # Feature 2 ------------------------------------------------------------------

  h3("Feature 2"),

  # fluidRow (Feature 2: file upload) -----
  fluidRow(

    # file upload sidebarLayout ----
    sidebarLayout(

      # file upload sidebarPanel ----
      sidebarPanel(

        # upload fileInput -----
        fileInput(inputId = "csv_input",
                  label = "Upload your CSV file:",
                  multiple = FALSE,
                  accept = c(".csv"),
                  buttonLabel = "Browse",
                  placeholder = "No file selected"), # END upload fileInput

      ), # END file upload sidebarPanel

      # fileInput mainPanel ----
      mainPanel(

        tableOutput(outputId = "summary_table_output")

      ) # END file upload mainPanel

    ) # END file upload sidebarLayout

  ), # END fluidRow (Feature 2: file upload)
  
) # END fluidPage 
```

## `server.R`

```{r filename="testing-app/server.R"}
#| eval: false
#| echo: true
server <- function(input, output) {
  
  # Feature 1 ------------------------------------------------------------------
  # wait for user to click the Greet button before returning the message
  observe({
    
    # if the user does not type anything, return the message, "Please type a name, then click the Greet button."
    if (nchar(input$name_input) == 0) {
      output$greeting_output <- renderText({
        "Please type a name, then click the Greet button."
      })
      
      # if the user does type a name, return the greeting, "Hello [name]!"
    } else {
      output$greeting_output <- renderText({
        paste0("Hello ", isolate(input$name_input), "!")
      })
    }
  }) |>
    
    # TODO: add description here
    bindEvent(input$greeting_button_input)
}
  
  # Feature 2 ------------------------------------------------------------------

  # file upload ----
  output$summary_table_output <- renderTable({

    # NOTE: `input$csv_input` will be NULL initially
    # after user selects / uploads a file, it will be a df with 'name', 'size', 'type', 'datapath' cols
    # 'datapath' col will contain the local filenames where data can be found
    # see: https://shiny.posit.co/r/reference/shiny/1.4.0/fileinput

    # save input value to object named `inputFile` ----
    inputFile <- input$csv_input

    # if a file has not been uploaded yet, don't return / print anything ----
    if(is.null(inputFile))
      return(NULL)

    # read in file using it's datapath ----
    df_raw <- read_csv(inputFile$datapath)

    # validate that the uploaded CSV has the expected column names ----
    required_cols <- c("temp_c", "precip_cm", "wind_kmhr", "pressure_inhg")
    column_names <- colnames(df_raw)
    validate(
      need(all(required_cols %in% column_names), "Your CSV does not have the expected column headers.")
    )

    # return summarized data in a table ----
    df_summary <- df_raw |>
      summarize(
        avg_temp = mean(temp_c),
        avg_precip = mean(precip_cm),
        avg_wind = mean(wind_kmhr),
        avg_pressure = mean(pressure_inhg),
        tot_num_obs = length(temp_c)
      ) |>
      rename("Mean Temperature (C)" = "avg_temp",
             "Mean Precipitation (cm)" = "avg_precip",
             "Mean Wind Speed (km/hr)" = "avg_wind",
             "Mean Pressure (inHg)" = "avg_pressure",
             "Total Number of Observations" = "tot_num_obs")
    return(df_summary)

  })
  
} # END server
```

:::

---

##  {#run-ft2-app data-menu-title="Run the app"}

[Run your app & play around with the new feature]{.slide-title2}

<hr>

You can practice uploading [this csv file, `real-sample-data.csv`](https://drive.google.com/file/d/1X3Y1J1pWX1OHNEcieyBpueL2MXOt5hWB/view?usp=drive_link), which is representative data that your team will want processed.

```{r}
#| eval: true
#| echo: false
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("images/part6/ft2-upload.gif")
```

<br>

::: {.center-text}
Your boss gives you the green light to start writing tests.
:::

---

##  {#ft2-assumptions data-menu-title="Feature 2 assumptions"}

[Begin by jotting down any assumptions you can think of]{.slide-title3}

<hr>

Chat with the person(s) next to you and try to come up with a few different actions / scenarios a user may encounter.

```{r}
countdown::countdown(
  minutes = 5,
  # left = 0, right = 0,
  # Fanfare when it's over
  # play_sound = TRUE,
  color_border              = "#FFFFFF",
  color_text                = "#7aa81e",
  color_running_background  = "#7aa81e",
  color_running_text        = "#FFFFFF",
  color_finished_background = "#ffa07a",
  color_finished_text       = "#FFFFFF",
  font_size = "2em",
  )
```

. . . 

| Action(s)                                                                                                                                              | Expectation(s)                                                                                     |
|--------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|
| Click Browse > Select CSV file with correct column headers and data                                                                                    | A table with renamed / averaged columns is returned                                                |
| Click Browse > Select CSV with incorrect column headers                                                                                                | An error message, "Your CSV does not have the expected column headers" is returned                 |
| Click Browse > Select empty CSV (no column headers or data)                                                                                            | An error message, "Your CSV does not have the expected column headers" is returned                 |
| Click Browse > Select CSV file with only column headers and no data                                                                                    | A table with renamed columns and NA values is returned                                             |
| Click Browse > Select CSV file with only data and no column headers                                                                                    | An error message, "Your CSV does not have the expected column headers" is returned                 |
| Click Browse > Select CSV file with correct column headers and data > Click Browse again > Select a different CSV with correct column headers and data | The second (most recent) uploaded data is the final returned table with renamed / averaged columns |

---

##  {#create-test-data data-menu-title="Create test data"}

[We'll also need some test data]{.slide-title}

<hr>

We'll need CSVs which can be used as representative examples for each of the scenarios we want to test for. This includes: 

- [two different CSVs, each with correct column headers / data]{.body-text-s}
- [one CSV with incorrect column headers]{.body-text-s} 
- [one completely blank CSV]{.body-text-s}
- [one CSV with column headers but missing data]{.body-text-s}
- [one CSV with data but missing column headers]{.body-text-s}

<br>

The test data do not necessarily need to be "real" (i.e. real measurements collected by instruments or people). They can be simple, short data sets, so long as they cover the scenarios we've discussed.

<br>

::: {.center-text .body-text-m}
**Download these test data [CSV files](https://drive.google.com/drive/folders/14VIirofAz04KwTyHqQ_8pbOK95IqUQ1H?usp=drive_link)**, which we'll use to create our tests.
:::

---

##  {#storing-test-data data-menu-title="Storing test data"}

[Store test data in `tests/testthat/`]{.slide-title}

<hr>

<br>

Whenever you record a file upload event to a `fileInput`, the test script will include a line similar to this,

<br>

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: false
app$uploadFile(file1 = "your-data.csv")
```

<br>

which indicates the file name, but not the file path. `{shinytest2}` will look for a test file with that name inside the `tests/testthat/` folder.

<br>

::: {.center-text .body-text-m}
**Copy all of our test files into `tests/testthat/` now.**
:::

---

##  {#ft2-test1 data-menu-title="Feature 2, test 1"}

[Okay, let's finally write our first test!]{.slide-title2}

<hr>

<br>

[**Repeat the steps from earlier:**]{.teal-text}

[[**(1)**]{.teal-text} Run `shinytest2::record_test("testing-app")` in the Console]{.body-text-s}

[[**(2)**]{.teal-text} Click Browse > select `cols-and-data1.csv` from wherever you have it saved (mine is on my Desktop) > click Expect Shiny Values]{.body-text-s}

[[**(3)**]{.teal-text} Give the test a unique name (e.g. `cols-and-data`) > click Save test and exit]{.body-text-s}

[[**(4)**]{.teal-text} The test recorder will quit, and your test will automatically execute]{.body-text-s}

<br>

. . . 

::: {.center-text .body-text-l}
What happens?
:::

. . .

::: {.center-text .body-text-l}
Our last three tests failed??? What???
:::

---

##  {#old-tests-fail data-menu-title="Old tests fail"}

[Explore the diffs in your Console]{.slide-title2}

<hr>

Your console should look similar to this:

```{r}
#| eval: false
#| echo: true
Listening on http://127.0.0.1:6451
{shiny} R stderr ----------- Loading required package: shiny
{shiny} R stderr ----------- Warning: package ‘shiny’ was built under R version 4.3.1
{shiny} R stderr ----------- Running application in test mode.
{shiny} R stderr ----------- Warning: package ‘ggplot2’ was built under R version 4.3.1
{shiny} R stderr ----------- Warning: package ‘dplyr’ was built under R version 4.3.1
{shiny} R stderr ----------- Warning: package ‘stringr’ was built under R version 4.3.1
{shiny} R stderr ----------- 
{shiny} R stderr ----------- Listening on http://127.0.0.1:5328
{shiny} R stdout ----------- ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
{shiny} R stdout ----------- ✔ dplyr     1.1.4     ✔ readr     2.1.4
{shiny} R stdout ----------- ✔ forcats   1.0.0     ✔ stringr   1.5.1
{shiny} R stdout ----------- ✔ ggplot2   3.5.0     ✔ tibble    3.2.1
{shiny} R stdout ----------- ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
{shiny} R stdout ----------- ✔ purrr     1.0.2     
{shiny} R stdout ----------- ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
{shiny} R stdout ----------- ✖ dplyr::filter() masks stats::filter()
{shiny} R stdout ----------- ✖ dplyr::lag()    masks stats::lag()
{shiny} R stdout ----------- ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors
{shiny} R stdout ----------- Rows: 4 Columns: 4
{shiny} R stdout ----------- ── Column specification ────────────────────────────────────────────────────────
{shiny} R stdout ----------- Delimiter: ","
{shiny} R stdout ----------- dbl (4): temp_c, precip_cm, wind_kmhr, pressure_inhg
{shiny} R stdout ----------- 
{shiny} R stdout ----------- ℹ Use `spec()` to retrieve the full column specification for this data.
{shiny} R stdout ----------- ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
• Saving test file: tests/testthat/test-shinytest2.R
• Modify '/Users/samanthacsik/git/EDS-430/testing-shiny-apps/testing-app/tests/testthat/test-shinytest2.R'
• Running recorded test: tests/testthat/test-shinytest2.R
Loading required package: testthat

Attaching package: ‘testthat’

The following object is masked from ‘package:dplyr’:

    matches

The following object is masked from ‘package:purrr’:

    is_null

The following objects are masked from ‘package:readr’:

    edition_get, local_edition

The following object is masked from ‘package:tidyr’:

    matches

✔ | F W  S  OK | Context
✖ | 3 5      1 | shinytest2 [7.3s]                                                                
──────────────────────────────────────────────────────────────────────────────────────────────────
Failure (test-shinytest2.R:7:3): {shinytest2} recording: one-name-greeting
Snapshot of `file` to 'shinytest2/one-name-greeting-001.json' has changed
Run testthat::snapshot_review('shinytest2/') to review changes
Backtrace:
    ▆
 1. └─app$expect_values() at test-shinytest2.R:7:3
 2.   └─shinytest2:::app_expect_values(...)
 3.     └─shinytest2:::app__expect_snapshot_file(...)
 4.       ├─base::withCallingHandlers(...)
 5.       └─testthat::expect_snapshot_file(...)

Warning (test-shinytest2.R:7:3): {shinytest2} recording: one-name-greeting
Diff in snapshot file `shinytest2one-name-greeting-001.json`
< before                                > after                               
@@ 1,9 @@                               @@ 1,11 @@                            
  {                                       {                                   
    "input": {                              "input": {                        
~                                       >     "csv_input": null,              
      "greeting_button_input": 1,             "greeting_button_input": 1,     
      "name_input": "Sam"                     "name_input": "Sam"             
    },                                      },                                
    "output": {                             "output": {                       
<     "greeting_output": "Hello Sam!"   >     "greeting_output": "Hello Sam!",
~                                       >     "summary_table_output": null    
    },                                      },                                
    "export": {                             "export": {                       

Failure (test-shinytest2.R:18:3): {shinytest2} recording: consecutive-name-greeting
Snapshot of `file` to 'shinytest2/consecutive-name-greeting-001.json' has changed
Run testthat::snapshot_review('shinytest2/') to review changes
Backtrace:
    ▆
 1. └─app$expect_values() at test-shinytest2.R:18:3
 2.   └─shinytest2:::app_expect_values(...)
 3.     └─shinytest2:::app__expect_snapshot_file(...)
 4.       ├─base::withCallingHandlers(...)
 5.       └─testthat::expect_snapshot_file(...)

Warning (test-shinytest2.R:18:3): {shinytest2} recording: consecutive-name-greeting
Diff in snapshot file `shinytest2consecutive-name-greeting-001.json`
< before                                > after                               
@@ 1,9 @@                               @@ 1,11 @@                            
  {                                       {                                   
    "input": {                              "input": {                        
~                                       >     "csv_input": null,              
      "greeting_button_input": 2,             "greeting_button_input": 2,     
      "name_input": "Kat"                     "name_input": "Kat"             
    },                                      },                                
    "output": {                             "output": {                       
<     "greeting_output": "Hello Kat!"   >     "greeting_output": "Hello Kat!",
~                                       >     "summary_table_output": null    
    },                                      },                                
    "export": {                             "export": {                       

Failure (test-shinytest2.R:25:3): {shinytest2} recording: no-name-greeting
Snapshot of `file` to 'shinytest2/no-name-greeting-001.json' has changed
Run testthat::snapshot_review('shinytest2/') to review changes
Backtrace:
    ▆
 1. └─app$expect_values() at test-shinytest2.R:25:3
 2.   └─shinytest2:::app_expect_values(...)
 3.     └─shinytest2:::app__expect_snapshot_file(...)
 4.       ├─base::withCallingHandlers(...)
 5.       └─testthat::expect_snapshot_file(...)

Warning (test-shinytest2.R:25:3): {shinytest2} recording: no-name-greeting
Diff in snapshot file `shinytest2no-name-greeting-001.json`
< before                                                                        
> after                                                                         
@@ 1,9 / 1,11 @@                                                                
  {                                                                             
    "input": {                                                                  
>     "csv_input": null,                                                        
      "greeting_button_input": 1,                                               
      "name_input": ""                                                          
    },                                                                          
    "output": {                                                                 
<     "greeting_output": "Hello !"                                              
>     "greeting_output": "Please type a name before clicking the Greet button.",
>     "summary_table_output": null                                              
    },                                                                          
    "export": {                                                                 

Warning (test-shinytest2.R:32:3): {shinytest2} recording: cols-and-data
Adding new file snapshot: 'tests/testthat/_snaps/cols-and-data-001_.png'

Warning (test-shinytest2.R:32:3): {shinytest2} recording: cols-and-data
Adding new file snapshot: 'tests/testthat/_snaps/cols-and-data-001.json'
──────────────────────────────────────────────────────────────────────────────────────────────────

══ Results ═══════════════════════════════════════════════════════════════════════════════════════
Duration: 7.6 s

── Failed tests ──────────────────────────────────────────────────────────────────────────────────
Failure (test-shinytest2.R:7:3): {shinytest2} recording: one-name-greeting
Snapshot of `file` to 'shinytest2/one-name-greeting-001.json' has changed
Run testthat::snapshot_review('shinytest2/') to review changes
Backtrace:
    ▆
 1. └─app$expect_values() at test-shinytest2.R:7:3
 2.   └─shinytest2:::app_expect_values(...)
 3.     └─shinytest2:::app__expect_snapshot_file(...)
 4.       ├─base::withCallingHandlers(...)
 5.       └─testthat::expect_snapshot_file(...)

Failure (test-shinytest2.R:18:3): {shinytest2} recording: consecutive-name-greeting
Snapshot of `file` to 'shinytest2/consecutive-name-greeting-001.json' has changed
Run testthat::snapshot_review('shinytest2/') to review changes
Backtrace:
    ▆
 1. └─app$expect_values() at test-shinytest2.R:18:3
 2.   └─shinytest2:::app_expect_values(...)
 3.     └─shinytest2:::app__expect_snapshot_file(...)
 4.       ├─base::withCallingHandlers(...)
 5.       └─testthat::expect_snapshot_file(...)

Failure (test-shinytest2.R:25:3): {shinytest2} recording: no-name-greeting
Snapshot of `file` to 'shinytest2/no-name-greeting-001.json' has changed
Run testthat::snapshot_review('shinytest2/') to review changes
Backtrace:
    ▆
 1. └─app$expect_values() at test-shinytest2.R:25:3
 2.   └─shinytest2:::app_expect_values(...)
 3.     └─shinytest2:::app__expect_snapshot_file(...)
 4.       ├─base::withCallingHandlers(...)
 5.       └─testthat::expect_snapshot_file(...)

[ FAIL 3 | WARN 5 | SKIP 0 | PASS 1 ]
Error: Test failures
```

::: {.center-text .body-text-s}
**What do you notice about each of the failed tests (taking a look at the `*_new.png` files may help)?**
:::

---

##  {#global-expectations-json1 data-menu-title="Global expectations (json, original)"}

[Global expectations have changed]{.slide-title}

<hr>

**Let's use our `one-name-greeting` test as an example** to understand why our first three tests of feature 1 (greeting input) failed.

<br>
<br>

:::: {.columns}

::: {.column width="50%"}
::: {.center-text .body-text-s}
`one-name-greeting-001.json`
:::
```{r}
#| eval: false
#| echo: true
{
  "input": {
    "greeting_button_input": 1,
    "name_input": "Sam"
  },
  "output": {
    "greeting_output": "Hello Sam!"
  },
  "export": {

  }
}
```
:::

::: {.column width="50%"}
- [When we first wrote our `one-name-greeting` test, our app had two possible inputs (`greeting_button_input` & `name_input`) for which we set known values, and one expected output (`greeting_output`). These are the ***only*** inputs and outputs our test recognizes.]{.body-text-s}

- [When the `one-name-greeting` test is run with our defined values (`Sam` & `1` button click), it expects the `greeting_output`, `Hello Sam!`, to be returned.]{.body-text-s}
:::
::::

---

##  {#global-expectations-json2 data-menu-title="Global expectations (json, new)"}

[Global expectations have changed]{.slide-title}

<hr>

**Let's use our `one-name-greeting` test as an example** to understand why our first three tests of feature 1 (greeting input) failed.

<br>
<br>

:::: {.columns}

::: {.column width="50%"}
::: {.center-text .body-text-s}
`one-name-greeting-001.new.json`
:::
```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "3,9"
{
  "input": {
    "csv_input": null,
    "greeting_button_input": 1,
    "name_input": "Sam"
  },
  "output": {
    "greeting_output": "Hello Sam!",
    "summary_table_output": null
  },
  "export": {

  }
}
```
:::

::: {.column width="50%"}
- [Adding feature 2 (file uploader) means that there is now an additional possible input (`csv_input`) and output (`summary_table_output`).]{.body-text-s}

- [Our original test does not define an input value or expected output value for `csv_input` and `summary_table_output`.]{.body-text-s}

- [When our test is run on our updated app, it sees the new `csv_input` and `summary_table_output`, which are both empty (`NULL`).]{.body-text-s}
:::
::::

<!-- . . .  -->

<!-- [When we first wrote our `one-name-greeting` test, our app had two possible inputs (`greeting_button_input` & `name_input`) for which we set known values, and one expected output (`greeting_output`). Adding feature 2 (file uploader) means that there is now an additional possible input (`csv_input`) and output (`summary_table_output`). When the `one-name-greeting` test is run with our defined values (`Sam` & `1` button click), it expects the `greeting_output`, `Hello Sam!`, to be returned. *However* our original test does not define an input value or expected output value for `csv_input` and `summary_table_output`. As a result these values are set to `NULL`.]{.body-text-s} -->

---

##  {#global-expectations-png data-menu-title="Global expectations (png)"}

[Global expectations have changed]{.slide-title}

<hr>

<br>

Checking out the snapshot PNGs side-by-side also can be helpful:

<br>

:::: {.columns}

::: {.column width="50%"}
::: {.center-text .body-text-s}
`one-name-greeting-001_.png`
:::
```{r}
#| eval: true
#| echo: false
#| out-width: "100%"
#| fig-align: "center"
knitr::include_graphics("images/part6/one-name-greeting-001_.png")
```
:::

::: {.column width="50%"}
::: {.center-text .body-text-s}
`one-name-greeting-001_.new.png`
:::
```{r}
#| eval: true
#| echo: false
#| out-width: "100%"
#| fig-align: "center"
knitr::include_graphics("images/part6/one-name-greeting-001_.new.png")
```
:::
::::

---

##  {#targetted-expectations data-menu-title="Targetted expectations"}

[We need to create tests with *targeted* value expectations]{.slide-title3}

<hr>

**By default, tests take snapshots of the *entire application***. Therefore, adding any new input(s) / output(s) will cause old tests to fail.

. . . 

<br>

*Which means* we'll need to redo / modify our tests {{< fa face-grin-beam-sweat title="a grinning face with a bead of sweat dripping from the brow" >}}

. . . 

<br>

*To start*, comment out all test code in `test-shinytest2.R` and click **Run Tests** -- you should see all your test snapshots disappear.

. . .

<br>

---

<!-- ##  {#testing-tips data-menu-title="Testing tips"} -->

<!-- [Tips for testing]{.slide-title} -->

<!-- <hr> -->

<!-- <p class="body-text topbr">[{{< fa angle-right title="a bullet point" >}}]{.teal-text} Record subsequent tests following the same workflow, giving each a unique name. Run `test_app("path/to/app")` to run all test scripts in your app's `tests/testhat/` directory.</p> -->

<!-- <p class="body-text">[{{< fa angle-right title="a bullet point" >}}]{.teal-text} **Use `record_test()` fairly often** -- Barret Schloerke argues that you should make a test recording for each feature of your app (many little recordings are encouraged!)</p> -->

<!-- <p class="body-text topbr">[{{< fa angle-right title="a bullet point" >}}]{.teal-text} **Limit testing to objects under your control.** For example, let's say you have a reactive data frame that you then send to a `DT::datatable` -- if package maintainers update the `DT` package, your output might change which could lead to false positive failed tests. Instead, test just your data frame that gets sent to `DT`.</p> -->

<!-- . . . -->

<!-- <br> -->

<!-- <center><p class="body-text-l teal-text">This is only a brief intro to `shinytest2`! Dig into the [documentation](https://rstudio.github.io/shinytest2/index.html) to learn more.</p></center> -->

---

##  {#end data-menu-title="~~~ BREAK ~~~" background="#047C90"}

<div class="page-center vertical-center">
<p class="custom-subtitle bottombr">End part 6.2</p>
<p class="caption-text">***Up next:** streamlining code*</p>
</div>

```{r}
countdown::countdown(
  minutes = 5,
  # left = 0, right = 0,
  # Fanfare when it's over
  # play_sound = TRUE,
  color_border              = "#FFFFFF",
  color_text                = "#7aa81e",
  color_running_background  = "#7aa81e",
  color_running_text        = "#FFFFFF",
  color_finished_background = "#ffa07a",
  color_finished_text       = "#FFFFFF",
  font_size = "2em",
  )
```

